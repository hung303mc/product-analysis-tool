import streamlit as st
import google.generativeai as genai
import gspread
from gspread_dataframe import set_with_dataframe
from google.oauth2.service_account import Credentials
import csv
import time
import json
import os
from datetime import datetime
import io
import pandas as pd
from streamlit_autorefresh import st_autorefresh


# T·∫°o m·ªôt "nh·ªãp tim" ƒë·ªÉ gi·ªØ k·∫øt n·ªëi s·ªëng, ch·∫°y 2 ph√∫t m·ªôt l·∫ßn (120 gi√¢y)
# T√≠n hi·ªáu n√†y ƒë·ªß ƒë·ªÉ b√°o cho c√°c t·∫ßng m·∫°ng bi·∫øt session v·∫´n ho·∫°t ƒë·ªông.
st_autorefresh(interval=2 * 60 * 1000, key="heartbeat_refresher")

# --- PAGE CONFIG ---
st.set_page_config(page_title="Product Analysis Tool", page_icon="üöÄ", layout="wide")

# --- AUTHENTICATION & SETUP ---
# Thi·∫øt l·∫≠p cho c·∫£ Gemini v√† Google Sheets
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    
    GCP_CREDS = st.secrets["gcp_service_account"]
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
    creds = Credentials.from_service_account_info(GCP_CREDS, scopes=SCOPES)
    gc = gspread.authorize(creds)

except Exception as e:
    st.error(f"L·ªói c√†i ƒë·∫∑t ho·∫∑c x√°c th·ª±c: {e}")
    st.info("H√£y ki·ªÉm tra l·∫°i file .streamlit/secrets.toml v√† ch·∫Øc ch·∫Øn m√†y ƒë√£ c·∫•u h√¨nh ƒë·ªß c·∫£ GOOGLE_API_KEY v√† gcp_service_account.")
    st.stop()

# --- PROMPT TEMPLATE (Gi·ªØ nguy√™n nh∆∞ code g·ªëc c·ªßa m√†y) ---
DEFAULT_PROMPT = """
M√†y l√† m·ªôt nh√† chi·∫øn l∆∞·ª£c t√¨m ki·∫øm c∆° h·ªôi trong th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠. M·ª•c ti√™u ch√≠nh c·ªßa m√†y l√† x√°c ƒë·ªãnh c√°c s·∫£n ph·∫©m "winner" M·ªöI cho m·ªôt doanh nghi·ªáp online linh ho·∫°t.

B·ªêI C·∫¢NH & QUY T·∫ÆC KINH DOANH:
1.  **M√¥ h√¨nh Logistics:** V·∫≠n chuy·ªÉn h√†ng kh√¥ng (Air freight) t·ª´ Trung Qu·ªëc v·ªÅ kho ·ªü M·ªπ. S·∫£n ph·∫©m kh√¥ng l∆∞u kho d√†i h·∫°n.
2.  **GI·ªöI H·∫†N C√ÇN N·∫∂NG NGHI√äM NG·∫∂T:** S·∫£n ph·∫©m > 4 lbs (~1.8 kg) s·∫Ω t·ª± ƒë·ªông b·ªã 'B·ªè qua' (Skip). L√Ω t∆∞·ªüng l√† d∆∞·ªõi 3 lbs (~1.4 kg).
3.  **L·ª£i nhu·∫≠n l√† tr√™n h·∫øt:** S·ª≠ d·ª•ng chi ph√≠ v·∫≠n chuy·ªÉn tham kh·∫£o (~$15 cho 1lb, ~$25 cho 2lbs, v.v.) ƒë·ªÉ ∆∞·ªõc t√≠nh l·ª£i nhu·∫≠n r√≤ng ti·ªÅm nƒÉng.
4.  **TH√ÄNH C√îNG BAN ƒê·∫¶U (ƒë·ªÉ tham kh·∫£o, kh√¥ng ph·∫£i gi·ªõi h·∫°n):** Doanh nghi·ªáp ƒë√£ c√≥ th√†nh c√¥ng b∆∞·ªõc ƒë·∫ßu v·ªõi ng√°ch "C√°c thi·∫øt b·ªã cho th·ªùi ti·∫øt n√≥ng" v√† "Ph·ª• ki·ªán th·ªùi trang m√πa h√®". H√£y d√πng th√¥ng tin n√†y l√†m ng·ªØ c·∫£nh ƒë·ªÉ nh·∫≠n di·ªán c√°c m√¥ th·ª©c th√†nh c√¥ng (v√≠ d·ª•: s·∫£n ph·∫©m ƒë·ªôc ƒë√°o gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ), nh∆∞ng TUY·ªÜT ƒê·ªêI KH√îNG ch·∫•m ƒëi·ªÉm th·∫•p cho c√°c s·∫£n ph·∫©m thu·ªôc ng√†nh h√†ng m·ªõi. M·ª•c ti√™u ch√≠nh l√† t√¨m ra NG√ÅCH TH√ÄNH C√îNG TI·∫æP THEO.
5.  **M·ª•c ti√™u c·ªët l√µi:** T√¨m ki·∫øm c√°c s·∫£n ph·∫©m ƒë·ªôc ƒë√°o, c√≥ ti·ªÅm nƒÉng viral, c√≥ th·ªÉ t√¨m ngu·ªìn t·ª´ 1688.

NHI·ªÜM V·ª§:
Ph√¢n t√≠ch L√î s·∫£n ph·∫©m d∆∞·ªõi ƒë√¢y v·ªõi t∆∞ duy c·ªüi m·ªü. M·ª•c ti√™u ch√≠nh c·ªßa m√†y l√† x√°c ƒë·ªãnh c√°c s·∫£n ph·∫©m "winner" ti·ªÅm nƒÉng ti·∫øp theo, b·∫•t k·ªÉ ch√∫ng thu·ªôc danh m·ª•c n√†o. Cung c·∫•p m·ªôt "overall_summary" chi·∫øn l∆∞·ª£c v√† sau ƒë√≥ ƒë√°nh gi√° T·ª™NG s·∫£n ph·∫©m.

D·ªØ li·ªáu l√¥ s·∫£n ph·∫©m (ƒë·ªãnh d·∫°ng CSV):
{product_batch_csv}

Ph√¢n t√≠ch v√† tr·∫£ l·ªùi trong m·ªôt ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá duy nh·∫•t. KH√îNG th√™m b·∫•t k·ª≥ vƒÉn b·∫£n n√†o b√™n ngo√†i ƒë·ªëi t∆∞·ª£ng JSON ch√≠nh.

C·∫•u tr√∫c ph·∫£n h·ªìi JSON ph·∫£i nh∆∞ sau:
{{
  "overall_summary": "string (T√≥m t·∫Øt chi·∫øn l∆∞·ª£c c·ªßa m√†y v·ªÅ l√¥ h√†ng, nh·∫•n m·∫°nh v√†o c√°c C∆† H·ªòI M·ªöI t·ªët nh·∫•t. Cung c·∫•p ph·∫ßn n√†y b·∫±ng ti·∫øng Vi·ªát.)",
  "product_analyses": [
    {{
      "asin": "string (ASIN c·ªßa s·∫£n ph·∫©m)",
      "classification": "string (Gi·ªØ nguy√™n c√°c thu·∫≠t ng·ªØ ti·∫øng Anh n√†y: Winner, High Potential, Potential, Skip)",
      "reason": "string (L√Ω do to√†n di·ªán c·ªßa m√†y, gi·∫£i th√≠ch t·∫°i sao ƒë√¢y c√≥ th·ªÉ l√† m·ªôt s·∫£n ph·∫©m win, ngay c·∫£ khi n√≥ ·ªü trong m·ªôt ng√°ch m·ªõi. Cung c·∫•p ph·∫ßn n√†y b·∫±ng ti·∫øng Vi·ªát.)",
      "viral_potential": "string (Gi·ªØ nguy√™n c√°c thu·∫≠t ng·ªØ ti·∫øng Anh n√†y: Low, Medium, High)",
      "uniqueness_score": "number (1-10, 1 l√† h√†ng ph·ªï th√¥ng, 10 l√† c·ª±c k·ª≥ ƒë·ªôc ƒë√°o)",
      "market_trend_score": "number (1-10, s·∫£n ph·∫©m n√†y ph√π h·ª£p v·ªõi c√°c xu h∆∞·ªõng hi·ªán t·∫°i ho·∫∑c m·ªõi n·ªïi ·ªü th·ªã tr∆∞·ªùng M·ªπ nh∆∞ th·∫ø n√†o)",
      "logistics_fit": "string (Gi·ªØ nguy√™n c√°c thu·∫≠t ng·ªØ ti·∫øng Anh n√†y: Good, Acceptable, Poor)",
      "estimated_shipping_cost": "number (∆Ø·ªõc t√≠nh c·ªßa m√†y b·∫±ng USD)",
      "profit_potential": "string (Gi·ªØ nguy√™n c√°c thu·∫≠t ng·ªØ ti·∫øng Anh n√†y: Low, Medium, High, Very High)",
      "risks": ["string (Li·ªát k√™ c√°c r·ªßi ro ch√≠nh b·∫±ng ti·∫øng Vi·ªát.)"]
    }}
  ]
}}
"""

# --- CORE FUNCTIONS ---
def analyze_product_batch_api(product_batch_list, model, prompt_template):
    # H√†m n√†y gi·ªØ nguy√™n
    if not product_batch_list: return None
    output = io.StringIO()
    fieldnames = product_batch_list[0].keys()
    writer = csv.DictWriter(output, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(product_batch_list)
    csv_string = output.getvalue()
    prompt = prompt_template.format(product_batch_csv=csv_string)
    try:
        response = model.generate_content(prompt)
        if response.parts:
            cleaned_text = response.text.strip().replace('```json', '').replace('```', '')
            return json.loads(cleaned_text)
        return None
    except Exception as e:
        st.error(f"L·ªói API ho·∫∑c JSON: {e}")
        return None

# --- STREAMLIT APP UI ---
def main():
    st.title("üöÄ C√¥ng C·ª• Ph√¢n T√≠ch S·∫£n Ph·∫©m")
    st.info("T·∫£i l√™n file CSV t·ª´ Helium 10 ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

    with st.expander("üìñ Xem h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng (Workflow)", expanded=False):
        st.markdown("""
        **C√¥ng c·ª• n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ l√†m vi·ªác v·ªõi file CSV ƒë∆∞·ª£c xu·∫•t ra t·ª´ tool Black Box c·ªßa Helium 10.**

        #### **Quy tr√¨nh l√†m vi·ªác:**
        1.  **üì• L·∫•y File Input:**
            * V√†o **Helium 10 Black Box**, l·ªçc s·∫£n ph·∫©m theo c√°c ti√™u ch√≠ m√†y mu·ªën.
            * Nh·∫•n n√∫t **"Export Data"** ƒë·ªÉ t·∫£i v·ªÅ file CSV.

        2.  **‚¨ÜÔ∏è T·∫£i File L√™n ƒê√¢y:**
            * K√©o v√† th·∫£ ho·∫∑c nh·∫•n v√†o n√∫t 'Browse files' ƒë·ªÉ t·∫£i file CSV v·ª´a download t·ª´ Helium 10 l√™n.

        3.  **‚öôÔ∏è (T√πy ch·ªçn) Tinh Ch·ªânh:**
            * ·ªû thanh b√™n tr√°i, m√†y c√≥ th·ªÉ ch·ªçn Model AI ho·∫∑c ƒëi·ªÅu ch·ªânh 'Batch Size' (s·ªë s·∫£n ph·∫©m x·ª≠ l√Ω m·ªói l·∫ßn).
            * N·∫øu c·∫ßn, m√†y c√≥ th·ªÉ s·ª≠a ƒë·ªïi Prompt ƒë·ªÉ thay ƒë·ªïi c√°ch AI ph√¢n t√≠ch.

        4.  **üöÄ B·∫Øt ƒê·∫ßu Ph√¢n T√≠ch:**
            * Nh·∫•n v√†o n√∫t **'B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch'** v√† ch·ªù c√¥ng c·ª• x·ª≠ l√Ω.
            * C√¥ng c·ª• s·∫Ω ƒë·ªçc file c·ªßa m√†y, g·ª≠i d·ªØ li·ªáu cho AI ph√¢n t√≠ch, v√† t·∫°o ra m·ªôt file k·∫øt qu·∫£ m·ªõi.

        5.  **üìÑ Xem & T·∫£i K·∫øt Qu·∫£:**
            * File output s·∫Ω bao g·ªìm c√°c c·ªôt d·ªØ li·ªáu g·ªëc quan tr·ªçng v√† c√°c c·ªôt ph√¢n t√≠ch m·ªõi t·ª´ AI (nh∆∞ `classification`, `reason`, `viral_potential`...).
            * Nh·∫•n n√∫t **'T·∫£i v·ªÅ file k·∫øt qu·∫£'** ƒë·ªÉ l∆∞u file CSV ƒë√£ ƒë∆∞·ª£c l√†m gi√†u th√¥ng tin v·ªÅ m√°y.
        """)
    
    # -- Sidebar c√†i ƒë·∫∑t --
    st.sidebar.header("C√†i ƒë·∫∑t Ph√¢n t√≠ch")
    model_name = st.sidebar.selectbox(
        "Ch·ªçn Model Gemini", 
        ('gemini-2.5-pro', 'gemini-1.5-pro', 'gemini-1.5-flash'),
        index=0, 
        help="2.5 Pro cho ch·∫•t l∆∞·ª£ng ph√¢n t√≠ch cao nh·∫•t."
    )
    batch_size = st.sidebar.slider("S·ªë s·∫£n ph·∫©m m·ªói l√¥", 5, 20, 10)

    # <<< TH√äM L·ª∞A CH·ªåN OUTPUT M·ªöI >>>
    st.sidebar.header("C√†i ƒë·∫∑t Output")
    output_option = st.sidebar.radio("Ch·ªçn ƒë·ªãnh d·∫°ng output:",
                                     ('T·∫£i File CSV', 'Ghi v√†o Google Sheet'),
                                     index=1)
                                     
    # C√°c tr∆∞·ªùng nh·∫≠p li·ªáu cho Google Sheet ch·ªâ hi·ªán ra khi c·∫ßn
    gsheet_id = ""
    if output_option == 'Ghi v√†o Google Sheet':
        gsheet_id = st.sidebar.text_input("ID c·ªßa Google Sheet 'KHO K·∫æT QU·∫¢'", 
                                        "1v0Ms4Mg1L5liXl-5pGRhWoIXSipS0E5z7zGT4G8-JAM")

    with st.expander("üìù Ch·ªânh s·ª≠a Prompt (N√¢ng cao)"):
        prompt_text = st.text_area("Prompt Template:", value=DEFAULT_PROMPT, height=400)

    uploaded_file = st.file_uploader("T·∫£i file CSV t·ª´ Helium 10 l√™n ƒë√¢y:", type=["csv"])

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"ƒê√£ t·∫£i l√™n th√†nh c√¥ng file '{uploaded_file.name}' v·ªõi {len(df)} s·∫£n ph·∫©m.")
            st.dataframe(df.head())
            
            # ∆Ø·ªõc t√≠nh th·ªùi gian
            num_products = len(df)
            time_per_batch_seconds = 60 
            num_batches = (num_products + batch_size - 1) // batch_size
            total_seconds = num_batches * time_per_batch_seconds
            minutes, seconds = divmod(int(total_seconds), 60)
            
            st.markdown(f"---")
            st.markdown(f"‚è≥ **Th·ªùi gian x·ª≠ l√Ω d·ª± ki·∫øn:** Kho·∫£ng **{minutes} ph√∫t {seconds} gi√¢y** cho `{num_products}` s·∫£n ph·∫©m.")
            st.caption("Th·ªùi gian th·ª±c t·∫ø c√≥ th·ªÉ thay ƒë·ªïi t√πy v√†o t·∫£i c·ªßa API.")
            
            if st.button("üöÄ B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", type="primary", use_container_width=True):
                if output_option == 'Ghi v√†o Google Sheet' and (not gsheet_id or gsheet_id == "D√ÅN_ID_FILE_KHO_K·∫æT_QU·∫¢_V√ÄO_ƒê√ÇY"):
                    st.error("L·ªói: Vui l√≤ng nh·∫≠p ID c·ªßa Google Sheet 'KHO K·∫æT QU·∫¢' v√†o thanh c√†i ƒë·∫∑t b√™n tr√°i.")
                    st.stop()
                
                # --- PH·∫¶N LOGIC X·ª¨ L√ù ƒê√É C√ì THANH TI·∫æN TR√åNH ---
                progress_bar = st.progress(0, text="ƒêang chu·∫©n b·ªã...")
                
                model = genai.GenerativeModel(model_name)
                all_products = df.to_dict('records')
                final_results = []
                batches = [all_products[i:i + batch_size] for i in range(0, len(all_products), batch_size)]
                
                for i, batch in enumerate(batches):
                    # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh v√† status text
                    status_text = f"ƒêang x·ª≠ l√Ω l√¥ {i+1}/{len(batches)}... Vui l√≤ng ch·ªù."
                    progress_bar.progress((i) / len(batches), text=status_text)

                    if not batch: continue
                    analysis_result = analyze_product_batch_api(batch, model, prompt_text)
                    time.sleep(2)
                    if analysis_result and 'product_analyses' in analysis_result:
                        batch_map = {row.get('ASIN'): row for row in batch if row.get('ASIN')}
                        for analysis in analysis_result['product_analyses']:
                            asin = analysis.get('asin')
                            if asin in batch_map:
                                original_row = batch_map[asin]
                                original_row.update(analysis)
                                if isinstance(original_row.get('risks'), list):
                                    original_row['risks'] = ', '.join(original_row['risks'])
                                final_results.append(original_row)
                    else:
                        st.warning(f"L√¥ {i+1} x·ª≠ l√Ω th·∫•t b·∫°i ho·∫∑c kh√¥ng c√≥ k·∫øt qu·∫£.")
                        for row in batch:
                            row['classification'] = 'API_ERROR'
                            final_results.append(row)
                
                progress_bar.progress(1.0, text="Ph√¢n t√≠ch AI ho√†n t·∫•t!")

                if not final_results:
                     st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c t·∫°o ra. Vui l√≤ng ki·ªÉm tra l·∫°i file input ho·∫∑c c√†i ƒë·∫∑t.")
                     st.stop()
                
                # 1. T·∫°o DataFrame ban ƒë·∫ßu
                temp_df = pd.DataFrame(final_results)

                # 2. ƒê·ªãnh nghƒ©a th·ª© t·ª± c·ªôt mong mu·ªën (copy t·ª´ file python c≈©)
                OUTPUT_COLUMN_ORDER = [
                    # Core Info
                    'ASIN', 'URL', 'Image URL', 'Title', 'Price', 'Parent Level Sales', 'Weight',
                    # Holistic Analysis
                    'classification', 'reason',
                    # Marketing & Strategy Scores
                    'viral_potential', 'uniqueness_score', 'market_trend_score',
                    # Logistics & Profitability Scores
                    'logistics_fit', 'estimated_shipping_cost', 'profit_potential',
                    # Risks
                    'risks'
                ]

                # 3. T·∫°o danh s√°ch c·ªôt cu·ªëi c√πng ƒë·ªÉ tr√°nh l·ªói KeyError
                # L·∫•y c√°c c·ªôt c√≥ trong list order v√† c≈©ng c√≥ trong dataframe
                final_ordered_columns = [col for col in OUTPUT_COLUMN_ORDER if col in temp_df.columns]
                # L·∫•y c√°c c·ªôt c√≤n l·∫°i trong dataframe m√† kh√¥ng c√≥ trong list order (ƒë·ªÉ kh√¥ng l√†m m·∫•t d·ªØ li·ªáu)
                other_columns = [col for col in temp_df.columns if col not in final_ordered_columns]

                # 4. S·∫Øp x·∫øp l·∫°i DataFrame
                result_df = temp_df[final_ordered_columns + other_columns]
                
                st.subheader("Xem Tr∆∞·ªõc K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                st.dataframe(result_df)

                # <<< LOGIC HI·ªÇN TH·ªä OUTPUT D·ª∞A TR√äN L·ª∞A CH·ªåN >>>
                if output_option == 'T·∫£i File CSV':
                    with st.spinner("ƒêang chu·∫©n b·ªã file CSV..."):
                        csv_output = result_df.to_csv(index=False).encode('utf-8-sig')
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        output_filename = f"{timestamp}_analyzed_{uploaded_file.name}"
                        st.download_button(
                            label="üì• T·∫£i v·ªÅ file k·∫øt qu·∫£ CSV",
                            data=csv_output,
                            file_name=output_filename,
                            mime='text/csv',
                            use_container_width=True
                        )
                
                elif output_option == 'Ghi v√†o Google Sheet':
                    with st.spinner("ƒêang t·∫°o tab m·ªõi v√† ghi d·ªØ li·ªáu v√†o Google Sheet..."):
                        timestamp = datetime.now().strftime("%y%m%d_%H%M")
                        worksheet_name = f"{timestamp}_{os.path.splitext(uploaded_file.name)[0]}"
                        
                        try:
                            spreadsheet = gc.open_by_key(gsheet_id)
                            template_sheet = spreadsheet.worksheet("Template")
                            worksheet = spreadsheet.duplicate_sheet(source_sheet_id=template_sheet.id, new_sheet_name=worksheet_name)
                            
                            set_with_dataframe(worksheet, result_df, row=1, col=2, include_index=False, include_column_header=True, resize=False)
                            
                            sheet_url = f"https://docs.google.com/spreadsheets/d/{gsheet_id}/edit#gid={worksheet.id}"
                            
                            st.balloons()
                            st.success("üéâ Ghi d·ªØ li·ªáu v√†o tab m·ªõi th√†nh c√¥ng!")
                            st.link_button("M·ªü Google Sheet", url=sheet_url, use_container_width=True)
                        
                        except gspread.exceptions.WorksheetNotFound:
                            st.error("L·ªói: Kh√¥ng t√¨m th·∫•y sheet c√≥ t√™n 'Template' trong file Google Sheet c·ªßa m√†y. H√£y t·∫°o m·ªôt sheet v√† ƒë·∫∑t t√™n ch√≠nh x√°c l√† 'Template'.")
                        except Exception as e:
                            st.error(f"L·ªói khi thao t√°c v·ªõi Google Sheet: {e}")

        except Exception as e:
            st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra: {e}")

if __name__ == "__main__":
    main()